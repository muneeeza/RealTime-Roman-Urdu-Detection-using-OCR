{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ztz_b6Aj7Mk5",
        "aZ89-J-d7Rdn",
        "pQvOXMfv7eV7",
        "gAaH8zXZ7vw5",
        "tPpbjqCm7oKA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ROMAN URDU TEXT RECOGNITION  \n",
        "\n",
        "####Text extraction using OCR, followed by a module that recognizes whether the text is in Roman Urdu or not\n",
        "\n",
        "##Group Members:\n",
        "\n",
        "####Muneeza Iftikhar (02-136212-012)\n",
        "\n",
        "####Hafsa Hafeez Siddiqui (02-136212-026)\n"
      ],
      "metadata": {
        "id": "wk_5ubOz7AMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing libraries and mounting drive"
      ],
      "metadata": {
        "id": "ztz_b6Aj7Mk5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw4Z_jZf6_Xo",
        "outputId": "4b26738d-6eb5-4df1-b6ac-58a6818c6ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install easyocr"
      ],
      "metadata": {
        "id": "A1bG4fQv7O52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994d19da-0e49-4d44-d95a-559da9803873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.18.0+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.82)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.3)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.4)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->easyocr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Live/Webcam Detection"
      ],
      "metadata": {
        "id": "aZ89-J-d7Rdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "KrHrITPM7aQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "\n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "metadata": {
        "id": "pg8S3iRl7cZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "pQvOXMfv7eV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import os\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  # Create a folder to save the images\n",
        "  folder_path = '/content/captured_images'\n",
        "  if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "  # Save the captured image in the folder\n",
        "  with open(os.path.join(folder_path, filename), 'wb') as f:\n",
        "    f.write(binary)\n",
        "\n",
        "  return os.path.join(folder_path, filename)\n",
        "\n",
        "def apply_preprocessing(filename):\n",
        "    # Open the image file.\n",
        "    with Image.open(filename) as img:\n",
        "        # Convert the image to greyscale.\n",
        "        grey_img = img.convert('L')\n",
        "\n",
        "        # Sharpen the image.\n",
        "        sharp_img = grey_img.filter(ImageFilter.SHARPEN)\n",
        "\n",
        "        # Resize the image.\n",
        "        resized_img = sharp_img.resize((400, 300))\n",
        "\n",
        "        # Save the pre-processed image.\n",
        "        resized_img.save(os.path.join(os.path.dirname(filename), 'preprocessed_' + os.path.basename(filename)))\n",
        "\n",
        "try:\n",
        "    filename = take_photo()\n",
        "    print('Saved to {}'.format(filename))\n",
        "\n",
        "    # Show the image which was just taken.\n",
        "    display(Image.open(filename))\n",
        "\n",
        "    # Apply pre-processing on the captured image.\n",
        "    apply_preprocessing(filename)\n",
        "    print('Pre-processed image saved as preprocessed_' + os.path.basename(filename))\n",
        "\n",
        "    # Show the pre-processed image.\n",
        "    display(Image.open(os.path.join(os.path.dirname(filename), 'preprocessed_' + os.path.basename(filename))))\n",
        "except Exception as err:\n",
        "    # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "    # grant the page permission to access it.\n",
        "    print(str(err))"
      ],
      "metadata": {
        "id": "z5r1iQe-BQ76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Extraction"
      ],
      "metadata": {
        "id": "gAaH8zXZ7vw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageFilter\n",
        "import easyocr\n",
        "import os\n",
        "\n",
        "# Assuming the captured image is saved as 'photo.jpg' in the '/content/captured_images' folder\n",
        "image_path = '/content/captured_images/photo.jpg'\n",
        "\n",
        "def extract_text_easy_ocr(image_path):\n",
        "    # Perform OCR\n",
        "    reader = easyocr.Reader(['en'])\n",
        "    result = reader.readtext(image_path)\n",
        "    text = ' '.join([line[1] for line in result])\n",
        "\n",
        "    # Return the extracted text\n",
        "    return text\n",
        "\n",
        "def run_easy_ocr(image_path):\n",
        "    extracted_text = extract_text_easy_ocr(image_path)\n",
        "    print(f'Extracted Text: ' + extracted_text)\n",
        "\n",
        "# Run OCR on the captured image\n",
        "run_easy_ocr(image_path)"
      ],
      "metadata": {
        "id": "IpeX_AczEGcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing of Urdu Dictonary"
      ],
      "metadata": {
        "id": "tPpbjqCm7oKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Roman-Urdu-Dictionary.txt'"
      ],
      "metadata": {
        "id": "ocBbeEfC7mn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def preprocess_dictionary(file_path):\n",
        "    # Step 1: Load the dictionary\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        roman_urdu_dict = f.readlines()\n",
        "\n",
        "    # Step 2: Clean the data\n",
        "    cleaned_dict = []\n",
        "    for entry in roman_urdu_dict:\n",
        "        entry = entry.strip()  # Remove leading and trailing whitespace\n",
        "        entry = entry.lower()  # Convert to lowercase\n",
        "        # Tokenization based on the first colon only\n",
        "        parts = entry.split(':', 1)\n",
        "        if len(parts) == 2:\n",
        "            word, meanings = parts\n",
        "            word = word.strip()\n",
        "            # Remove punctuation from the word\n",
        "            word = word.translate(str.maketrans('', '', string.punctuation))\n",
        "            # Split meanings on slashes and commas\n",
        "            meanings_list = [meaning.strip() for meaning in re.split(r'[/,]', meanings)]\n",
        "            for meaning in meanings_list:\n",
        "                cleaned_dict.append((word, meaning))\n",
        "\n",
        "    # Step 3: Remove duplicate entries (if any)\n",
        "    unique_entries = set(cleaned_dict)\n",
        "\n",
        "    # Step 4: Organize the data\n",
        "    organized_dict = {}\n",
        "    for word, meaning in unique_entries:\n",
        "        if word in organized_dict:\n",
        "            organized_dict[word].add(meaning)\n",
        "        else:\n",
        "            organized_dict[word] = {meaning}\n",
        "\n",
        "    # Convert sets to lists for easier usage later\n",
        "    for word in organized_dict:\n",
        "        organized_dict[word] = list(organized_dict[word])\n",
        "\n",
        "    return organized_dict\n",
        "\n",
        "# Example usage:\n",
        "preprocessed_dict = preprocess_dictionary(file_path)\n",
        "\n",
        "# Now, preprocessed_dict contains the cleaned and organized Roman Urdu dictionary\n",
        "# You can use this dictionary in your OCR task for identifying and categorizing Roman Urdu words.\n",
        "\n",
        "# import pprint  # Pretty print to visualize the dictionary\n",
        "# pprint.pprint(preprocessed_dict)\n"
      ],
      "metadata": {
        "id": "ctrbt8ur7sSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roman Urdu Module"
      ],
      "metadata": {
        "id": "Zj983_Qn70sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "id": "XPR9EwXK72p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import nltk\n",
        "from nltk.corpus import words\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    roman_urdu_words_set = set(line.strip() for line in file)\n",
        "\n",
        "def run_easy_ocr(image_path):\n",
        "    # \"\"\"\n",
        "    # Run OCR on an image.\n",
        "    # Args:\n",
        "    #     image_path (str): The path to the image to run OCR on.\n",
        "    # Returns:\n",
        "    #     str: The extracted text.\n",
        "    # \"\"\"\n",
        "    english_words = set(words.words())  # Load English dictionary\n",
        "    all_roman_urdu_words = []  # List to store all Roman Urdu words\n",
        "    all_english_words = []  # List to store all English words\n",
        "\n",
        "    extracted_text = extract_text_easy_ocr(image_path)\n",
        "\n",
        "    words_in_text = extracted_text.split()  # Split the text into words\n",
        "    roman_urdu_words = []\n",
        "    english_words_in_text = []\n",
        "\n",
        "    for word in words_in_text:\n",
        "        if word.lower() in roman_urdu_words_set:  # Check if the word is in your Roman Urdu dictionary\n",
        "            roman_urdu_words.append(word)  # It's likely Roman Urdu\n",
        "        elif word.lower() not in english_words:  # Check if the word is not in the English dictionary\n",
        "            roman_urdu_words.append(word)  # It's likely Roman Urdu\n",
        "        else:\n",
        "            english_words_in_text.append(word)  # It's an English word\n",
        "\n",
        "    print(f'Extracted Text: {extracted_text}')\n",
        "    print(f'Roman Urdu Words: {roman_urdu_words}')  # Print the Roman Urdu words\n",
        "    print(f'English Words: {english_words_in_text}')  # Print the English words\n",
        "\n",
        "    all_roman_urdu_words.extend(roman_urdu_words)  # Add Roman Urdu words to the list\n",
        "    all_english_words.extend(english_words_in_text)  # Add English words to the list\n",
        "\n",
        "    # print(\"All Roman Urdu Words:\", all_roman_urdu_words)  # Print the list of all Roman Urdu words\n",
        "    # print(\"All English Words:\", all_english_words)  # Print the list of all English words\n",
        "\n",
        "run_easy_ocr(image_path)"
      ],
      "metadata": {
        "id": "rDM8dEfHFVzy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}